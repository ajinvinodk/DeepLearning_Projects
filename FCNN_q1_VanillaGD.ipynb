{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAw3c06ImuuZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LryYrxvwm_GA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3QZKXGWm_Qm"
      },
      "outputs": [],
      "source": [
        "X_train = np.load('/content/drive/MyDrive/Colab Notebooks/CS671/Assignment_2/X_train.npy')\n",
        "y_train = np.load('/content/drive/MyDrive/Colab Notebooks/CS671/Assignment_2/y_train.npy')\n",
        "X_test = np.load('/content/drive/MyDrive/Colab Notebooks/CS671/Assignment_2/X_test.npy')\n",
        "y_test = np.load('/content/drive/MyDrive/Colab Notebooks/CS671/Assignment_2/y_test.npy')\n",
        "X_validation = np.load('/content/drive/MyDrive/Colab Notebooks/CS671/Assignment_2/X_validation.npy')\n",
        "y_validation = np.load('/content/drive/MyDrive/Colab Notebooks/CS671/Assignment_2/y_validation.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Li2OK7Vm_ZX"
      },
      "outputs": [],
      "source": [
        "plt.subplot(2,3,1),plt.imshow(X_train[0].reshape(28,28))\n",
        "plt.subplot(2,3,2),plt.imshow(X_train[2277].reshape(28,28))\n",
        "plt.subplot(2,3,3),plt.imshow(X_train[4554].reshape(28,28))\n",
        "plt.subplot(2,3,4),plt.imshow(X_train[6831].reshape(28,28))\n",
        "plt.subplot(2,3,5),plt.imshow(X_train[9108].reshape(28,28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jXtHd9mkQqY"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "For selecting number of neurons in hidden layer\n",
        "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
        "\"\"\"\n",
        "dummy = list(zip(X_train, y_train))\n",
        "random.shuffle(dummy)\n",
        "X_train, y_train = zip(*dummy)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "dummy = list(zip(X_test, y_test))\n",
        "random.shuffle(dummy)\n",
        "X_test, y_test = zip(*dummy)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "dummy = list(zip(X_validation, y_validation))\n",
        "random.shuffle(dummy)\n",
        "X_validation, y_validation = zip(*dummy)\n",
        "X_validation = np.array(X_validation)\n",
        "y_validation = np.array(y_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OFWZohNzTRb"
      },
      "outputs": [],
      "source": [
        "plt.subplot(2,3,1),plt.imshow(X_train[10].reshape(28,28))\n",
        "print(y_train[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeGksYv3m_iH"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='sigmoid', name='hidden_layer_1', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(32, activation='sigmoid', name='hidden_layer_2'),\n",
        "    tf.keras.layers.Dense(16, activation='sigmoid', name='hidden_layer_3'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0.0001,\n",
        "    patience=100,\n",
        "    verbose=0,\n",
        "    mode=\"min\",\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),  # Giving 1 to max probability, taking max probability as summation(-p*ln(p))\n",
        "    metrics = ['accuracy'] # Since using one hot encoding, therefore using binary accuracy\n",
        ")\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=5000, batch_size=len(X_train), verbose=1,\n",
        "          validation_data = (X_validation, y_validation),\n",
        "          callbacks=[callback, model_checkpoint_callback]\n",
        ")\n",
        "\n",
        "model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFCmA5-Zm_pO"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = history.history['accuracy']\n",
        "avg_training_error=[]\n",
        "j=1;\n",
        "for i in dummy:\n",
        "  avg_training_error.append((j,1-i))\n",
        "  j+=1\n",
        "  \n",
        "plt.plot(*zip(*avg_training_error))\n",
        "plt.title('Average training error vs epochs')\n",
        "plt.ylabel('Average training error')\n",
        "plt.xlabel('epochs')\n",
        "plt.savefig(\"/content/average_training_error_vs_epoch.png\")"
      ],
      "metadata": {
        "id": "qR7PumEh8rtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfElGyiAm_vm"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.savefig(\"/content/model_accuracy.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVcsq1mzm_1m"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.savefig(\"/content/model_loss.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVMeMjz-m_7Q"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7p8yY_7uHBg"
      },
      "outputs": [],
      "source": [
        "plt.subplot(2,3,1),plt.imshow(X_test[10].reshape(28,28))\n",
        "print(y_test[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFbjJfXDnAAn"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_test)\n",
        "y_pred_test = []\n",
        "for dummy in pred:\n",
        "    dummy1 = (np.argmax(dummy, axis=0))\n",
        "    y_pred_test.append(dummy1)\n",
        "\n",
        "y_test_1 = []\n",
        "for dummy in y_test:\n",
        "    dummy1 = (np.argmax(dummy, axis=0))\n",
        "    y_test_1.append(dummy1)\n",
        "\n",
        "y_pred_test = np.array(y_pred_test)\n",
        "\n",
        "cf_matrix_test = confusion_matrix(y_test_1, y_pred_test)\n",
        "print(cf_matrix_test)\n",
        "\n",
        "x_axis_labels = [2,4,6,7,8]\n",
        "y_axis_labels = [2,4,6,7,8]\n",
        "cf_matrix_test_plot = sns.heatmap(cf_matrix_test, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot=True, fmt='g')   # fmt='g': general format, annot:If True, write the data value in each cell.\n",
        "fig = cf_matrix_test_plot.get_figure()\n",
        "fig.savefig(\"confusion_matrix_test.png\") "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_train)\n",
        "y_pred = []\n",
        "\n",
        "for dummy in pred:\n",
        "    dummy1 = (np.argmax(dummy, axis=0))\n",
        "    y_pred.append(dummy1)\n",
        "\n",
        "y_train_1 = []\n",
        "for dummy in y_train:\n",
        "    dummy1 = (np.argmax(dummy, axis=0))\n",
        "    y_train_1.append(dummy1)\n",
        "\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "cf_matrix_train = confusion_matrix(y_train_1, y_pred)\n",
        "print(cf_matrix_train)\n",
        "\n",
        "x_axis_labels = [2,4,6,7,8]\n",
        "y_axis_labels = [2,4,6,7,8]\n",
        "cf_matrix_train_plot = sns.heatmap(cf_matrix_train, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot=True, fmt='g')    # fmt='g': general format, annot:If True, write the data value in each cell.\n",
        "fig = cf_matrix_train_plot.get_figure()\n",
        "fig.savefig(\"confusion_matrix_train.png\")"
      ],
      "metadata": {
        "id": "hlH55-yECxUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_validation)\n",
        "y_pred_validation = []\n",
        "for dummy in pred:\n",
        "    dummy1 = (np.argmax(dummy, axis=0))\n",
        "    y_pred_validation.append(dummy1)\n",
        "\n",
        "y_validation_1 = []\n",
        "for dummy in y_validation:\n",
        "    dummy1 = (np.argmax(dummy, axis=0))\n",
        "    y_validation_1.append(dummy1)\n",
        "\n",
        "y_pred_validation = np.array(y_pred_validation)\n",
        "\n",
        "cf_matrix_validation = confusion_matrix(y_validation_1, y_pred_validation)\n",
        "print(cf_matrix_validation)\n",
        "\n",
        "x_axis_labels = [2,4,6,7,8]\n",
        "y_axis_labels = [2,4,6,7,8]\n",
        "cf_matrix_validation_plot = sns.heatmap(cf_matrix_validation, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot=True, fmt='g')   # fmt='g': general format, annot:If True, write the data value in each cell.\n",
        "fig = cf_matrix_validation_plot.get_figure()\n",
        "fig.savefig(\"confusion_matrix_validation.png\") "
      ],
      "metadata": {
        "id": "t7FmrhQ04CdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd7J8oOCnARi"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Test Accuracy: %.3f' % acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "FCNN_q1_VanillaGD.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}